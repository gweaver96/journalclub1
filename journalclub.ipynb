{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbobzqLK56Mk98AjYLHzMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gweaver96/journalclub1/blob/main/journalclub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look, I made a thing to teach you about stuff. Let me explain."
      ],
      "metadata": {
        "id": "pg3d85V4UHvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gweaver96/journalclub1"
      ],
      "metadata": {
        "id": "o10f1N9H8Bl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sxynFcOXUEtv"
      },
      "outputs": [],
      "source": [
        "#Import all the stuff\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "import pandas\n",
        "pandas.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's loads of stuff here, but I'm going to pretend I know enough to explain it all.\n",
        "\n",
        "\n",
        "The thing you just imported: **Tensorflow**, is the API that you use to write lots of different Machine Learning algorithms, and **Keras** is a more user-friendly wrapper on top of that. There are other APIs available, like PyTorch, but I've never used them and I'm scared of change. \n",
        "\n"
      ],
      "metadata": {
        "id": "muy4f_DBVbJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We're going to load the data now.\n",
        "# I'm not going to explain this cause I'm guessing you understand how to do this already.\n",
        "\n",
        "dataset = pandas.read_csv(\"/content/journalclub1/data.csv\")\n",
        "data = dataset.values\n",
        "header = dataset.columns\n",
        "dataset"
      ],
      "metadata": {
        "id": "jwCUydS2UHUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SO THEN\n",
        "\n",
        "We have our data - the measurement of stinkiness at a range of distances from Walley's Quarry. After loading it all in, now we have a dataset that is made up of 3 columns;\n",
        "\\\n",
        "1 - A useless numbered column going from 0 to 199 that I didn't know how to get rid of. \\\n",
        "2 - The distance in metres from the site. \\\n",
        "3 - The stinkiness rating, a scale in 'stinks per metre\\^3' from 0 to 1, where 1 is the maximum stinkiness. \\\n",
        "\\\n",
        "We can plot the data on a graph below to see what it looks like. Again I can't be bothered explaining how matplotlib works."
      ],
      "metadata": {
        "id": "ct5JhZE_QcCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter(dataset['Distance / metres (m)'], dataset['Stinkiness / stinks per metre^3 (st/m^3)'], s=10)\n",
        "plt.grid(True)\n",
        "plt.ylabel('Stinkiness / stinks per metre^3 (st/m^3)')\n",
        "plt.xlabel('Distance / metres (m)')\n",
        "plt.title('Stinkiness vs Distance from Walley\\'s Quarry')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HClFOcnsNrn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we're doing stuff you might not have used before.\n",
        "\n",
        "So in order to train our model we have to do 2 things. Firstly, we need to scale the data to between 0 and 1. Luckily, the scale of st/m^3 is already between 0 and 1, so we only have to do it for the distance measurements.\n",
        "\\\n",
        "\\\n",
        "This scaling makes it easier for the stupid machine to learn properly, as all the features (inputs) and labels (outputs) are in a similar range.\n",
        "There's a load of ways to do this in an annoying and complicated way but we're just going to scale it from minimum to maximum, between 0 and 1 with the MinMax scaler from sklearn."
      ],
      "metadata": {
        "id": "9QZvcbiRWsdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x = dataset['Distance / metres (m)']\n",
        "y = dataset['Stinkiness / stinks per metre^3 (st/m^3)']\n",
        "\n",
        "#setting the scale to not quite zero is good practice, because the stupid computer is too stupid to deal with values at the bounds\n",
        "scale_x = MinMaxScaler(feature_range=(0.001,1.000))\n",
        "\n",
        "#we make the x variable an array and reshape it into 2D for reasons literally impossible to understand\n",
        "x_scaled = scale_x.fit_transform(np.array(x).reshape(-1,1))\n",
        "\n",
        "plt.scatter(x_scaled, y, s=10)"
      ],
      "metadata": {
        "id": "tgrZO5wkXrdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look! Now it's all between 0 and 1 almost!\n",
        "\n",
        "Next we split the data into test and train sets. We will use the testing set later on to check if the model is good or not, and the training set is used to train the actual model we make."
      ],
      "metadata": {
        "id": "q1mrH7aJZZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size = 0.005, shuffle=True)\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter(x_train, y_train, c='k', s = 10, label = 'training data')\n",
        "plt.scatter(x_test, y_test, c='r', s=10, label = 'test data')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylabel('Stinkiness / stinks per metre^3 (stm^-3)')\n",
        "plt.xlabel('Scaled Distance')\n",
        "plt.title('Stinkiness vs Distance from Walley\\'s Quarry')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "525EmXheSYLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we do an actual model. Hold on to your seatbelts."
      ],
      "metadata": {
        "id": "bvJukwGNZtl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a Sequential model, with an output and an input layer, of one node each\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=1, input_dim=1))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "#compile it with a loss function and an optimiser\n",
        "model.compile(loss=keras.losses.MeanAbsoluteError(), optimizer=keras.optimizers.Adam(learning_rate=0.01))\n",
        "# this summary will tell us what the model is like\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "fb-J0tmxZxem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we fit the model to the training data, over 20 epochs, and with 20% of the data used to validate training.\n",
        "hist = model.fit(x_train, y_train, epochs=100, verbose=1, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "iecPWEwgadzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay I don't know about you but I can't be bothered trying to figure out what's happening with all those numbers.\n",
        "\n",
        "I need myself a great big lovely graph to show me what's going on. Let's plot the loss vs epochs below."
      ],
      "metadata": {
        "id": "ErrSVXZFPm0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(hist):\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.plot(hist.history['loss'], label='loss')\n",
        "  plt.plot(hist.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "plot_loss(hist)"
      ],
      "metadata": {
        "id": "tCQhTBZ2Ln-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_pred = np.linspace(0,1,10)\n",
        "y_pred = model(x_pred)"
      ],
      "metadata": {
        "id": "hJsytu2jak1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "plt.plot(x_pred, y_pred, c='r', lw=2, label = 'model prediction')\n",
        "plt.scatter(x_train, y_train, c='k', label = 'training data')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylabel('Stinkiness / stinks per metre^3 (stm^-3)')\n",
        "plt.xlabel('Scaled Distance')\n",
        "plt.title('Stinkiness vs Distance from Walley\\'s Quarry')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sUnRfiFNa37J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay I mean maybe for George work that's a good fit, but for actual scientists we probably need to make a more complex model.\n",
        "\n",
        "So let's do it.\n",
        "\n",
        "Literally all we need to do is add more layers to the model, but this time we use activation functions to change the outputs of the layers."
      ],
      "metadata": {
        "id": "QcxzyvfCTluQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=1, input_dim=1))\n",
        "\n",
        "model.add(Dense(units=50, activation = 'ReLU'))\n",
        "\n",
        "model.add(Dense(units=100, activation = 'ReLU'))\n",
        "\n",
        "model.add(Dense(units=200, activation = 'ReLU'))\n",
        "\n",
        "model.add(Dense(units=400, activation = 'ReLU'))\n",
        "\n",
        "model.add(Dense(units=200, activation = 'ReLU'))\n",
        "\n",
        "model.add(Dense(units=100, activation = 'ReLU'))\n",
        "\n",
        "model.add(Dense(units=50, activation = 'ReLU'))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "JcwXNtGxcxL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hot dang it look at the number of trainable parameters on that bad boy."
      ],
      "metadata": {
        "id": "2j0QsCNpULm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train it."
      ],
      "metadata": {
        "id": "tteN__lcULrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, y_train, epochs=1000, verbose=1, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "h0Mydhk1cxL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(hist)"
      ],
      "metadata": {
        "id": "oCU0JgQiUfAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay looking at that loss plot, we're doing a thing called overfitting. Maybe I got too excited when I made a model that had way more trainable parameters as there are data points.\n",
        "\n",
        "Run the next cell to see how the prediction looks. If there's loads of wiggly bits then we're definitely overfitting.\n",
        "\n",
        "Go back and fix my shoddy work."
      ],
      "metadata": {
        "id": "rg429KHtUmhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_pred = np.linspace(0,1,1000)\n",
        "y_pred = model(x_pred)\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "plt.plot(x_pred, y_pred, c='r', linewidth=3, label = 'model prediction')\n",
        "plt.scatter(x_train, y_train, c='k', label = 'training data')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.ylabel('Stinkiness / stinks per metre^3 (stm^-3)')\n",
        "plt.xlabel('Distance')\n",
        "plt.title('Stinkiness vs Distance from Walley\\'s Quarry')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4ZqneYpmc3Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMWPl6uMc8Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 'Okay okay okay okay, but so what. I can do that way quicker with np.polyfit?' I can hear Joe shout.\n",
        "\n",
        "Well well well, you poor, silly little lamb, let me show you the same thing, but in more than 2-D!"
      ],
      "metadata": {
        "id": "COfe9OJinMhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prod_data = pandas.read_csv(\"/content/journalclub1/data2.csv\")\n",
        "prod_data"
      ],
      "metadata": {
        "id": "N1jlFIoAnlFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter(prod_data['x_pos'], prod_data['y_pos'], c=prod_data['prod'], cmap = 'RdYlGn', s=100)\n",
        "plt.ylabel('Y Distance (m)')\n",
        "plt.xlabel('X Distance (m)')\n",
        "plt.title('Productivity with distance from Joe, Joe at (0,0)')\n",
        "plt.colorbar(label = 'Productivity')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter(prod_data['x_pos'], prod_data['y_pos'], c=prod_data['temp'], cmap = 'coolwarm', s=100)\n",
        "plt.ylabel('Y Distance (m)')\n",
        "plt.xlabel('X Distance (m)')\n",
        "plt.title('Temperature with distance from Joe, Joe at (0,0)')\n",
        "plt.colorbar(label = 'Temperature/Celsius')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tkUGNDrYryfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.hstack((np.array(prod_data['x_pos']).reshape(-1,1), np.array(prod_data['y_pos']).reshape(-1,1), np.array(prod_data['temp']).reshape(-1,1)))\n",
        "y = np.array(prod_data['prod']).reshape(-1,1)\n",
        "\n",
        "#setting the scale to not quite zero is good practice, because the stupid computer is too stupid to deal with values at the bounds\n",
        "scale = MinMaxScaler(feature_range=(0.001,0.999))\n",
        "scaley = MinMaxScaler(feature_range=(0.001,0.999))\n",
        "\n",
        "x_scaled = scale.fit_transform(np.array(x))\n",
        "y_scaled = scaley.fit_transform(np.array(y))\n",
        "\n",
        "plt.scatter(x_scaled[:,0], x_scaled[:,1], c=y_scaled, cmap = 'RdYlGn')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "05iPWUPOvSlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size = 0.01, shuffle=True)"
      ],
      "metadata": {
        "id": "mc4OELH1vSrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=3, input_dim=3))\n",
        "\n",
        "#PUT YOUR MODEL HERE\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss= ..., optimizer=keras.optimizers.Adam(learning_rate=...))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "wxuJpcGrskXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, y_train, epochs=..., verbose=1, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "UWLbFWXAvHqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(hist)"
      ],
      "metadata": {
        "id": "8RwCxKnbxH7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model(x_scaled)\n",
        "y_pred = scaley.inverse_transform(y_pred)\n",
        "\n",
        "yerr = y_pred - y\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter(prod_data['x_pos'], prod_data['y_pos'], c=y_pred, cmap = 'RdYlGn', s=100)\n",
        "plt.ylabel('Y Distance (m)')\n",
        "plt.xlabel('X Distance (m)')\n",
        "plt.title('Productivity with distance from Joe, Joe at (0,0)')\n",
        "plt.colorbar(label = 'Productivity')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter(prod_data['x_pos'], prod_data['y_pos'], c=yerr, s=100)\n",
        "plt.ylabel('Y Distance (m)')\n",
        "plt.xlabel('X Distance (m)')\n",
        "plt.title('Productivity with distance from Joe, Joe at (0,0)')\n",
        "plt.colorbar(label = 'Productivity Error')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter(prod_data['temp'], prod_data['prod'], c=yerr, s=100)\n",
        "plt.ylabel('Temp/C')\n",
        "plt.xlabel('Productivity')\n",
        "plt.title('Productivity vs Temp')\n",
        "plt.colorbar(label = 'Productivity Error')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter(prod_data['prod'], y_pred, c=yerr, cmap = 'RdYlGn', s=100)\n",
        "plt.ylabel('predicted productivity')\n",
        "plt.xlabel('Productivity')\n",
        "plt.title('Productivity vs Predictions')\n",
        "plt.colorbar(label = 'Productivity Error')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3BTwATxhxjlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1B0xlFlmxjsF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}